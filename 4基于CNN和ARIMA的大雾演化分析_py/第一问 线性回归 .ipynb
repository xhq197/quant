{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å¯¼å…¥æ•°æ®\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ptu15 = pd.read_csv('PTU_R06_15.csv')\n",
    "vis15 = pd.read_csv('VIS_R06_15.csv')\n",
    "wind15 = pd.read_csv('WIND_R06_15.csv')\n",
    "\n",
    "ptu12 = pd.read_csv('PTU_R06_12.csv')\n",
    "vis12 = pd.read_csv('VIS_R06_12.csv')\n",
    "wind12 = pd.read_csv('WIND_R06_12.csv')\n",
    "\n",
    "\n",
    "# ä¿®æ”¹ptu15åˆ—å\n",
    "ptu15.columns = ['CREATEDATE', 'LOCALDATE (BEIJING)', 'SITE', 'PAINS',\n",
    "       'QNH AERODROME', 'ST', 'QFE R06', 'ST.1', 'QFE R24',\n",
    "       'ST.2', 'QFF AERODROME', 'TREND', 'TENDENCY', 'TEMP',\n",
    "       'RH', 'DEWPOINT', 'TU DATA']\n",
    "\n",
    "ptu15_select = ptu15[['CREATEDATE','LOCALDATE (BEIJING)','SITE','PAINS','QFE R06','QNH AERODROME','TEMP','RH','DEWPOINT']]\n",
    "\n",
    "ptu12.columns = ['CREATEDATE', 'LOCALDATE (BEIJING)', 'SITE', 'PAINS',\n",
    "       'QNH AERODROME', 'ST', 'QFE R06', 'ST.1', 'QFE R24',\n",
    "       'ST.2', 'QFF AERODROME', 'TREND', 'TENDENCY', 'TEMP',\n",
    "       'RH', 'DEWPOINT', 'TU DATA']\n",
    "ptu12_select = ptu12[['CREATEDATE','LOCALDATE (BEIJING)','SITE','PAINS','QFE R06','QNH AERODROME','TEMP','RH','DEWPOINT']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# å¯¹VISã€WINDè¡¨åŒæ—¶é—´æˆ³æ•°æ®å–å¹³å‡\n",
    "vis15_mean = vis15[['CREATEDATE','LOCALDATE (BEIJING)','SITE','RVR_1A','MOR_1A','LIGHTS']].groupby(by = ['CREATEDATE','LOCALDATE (BEIJING)','SITE']).mean().reset_index()\n",
    "vis12_mean = vis12[['CREATEDATE','LOCALDATE (BEIJING)','SITE','RVR_1A','MOR_1A','LIGHTS']].groupby(by = ['CREATEDATE','LOCALDATE (BEIJING)','SITE']).mean().reset_index()\n",
    "wind15_mean = wind15[['CREATEDATE','LOCALDATE (BEIJING)','SITE','WS2A (MPS)','WD2A','CW2A (MPS)']].groupby(by = ['CREATEDATE','LOCALDATE (BEIJING)','SITE']).mean().reset_index()\n",
    "wind12_mean = wind12[['CREATEDATE','LOCALDATE (BEIJING)','SITE','WS2A (MPS)','WD2A','CW2A (MPS)']].groupby(by = ['CREATEDATE','LOCALDATE (BEIJING)','SITE']).mean().reset_index()\n",
    "\n",
    "#å¹¶å¯¹å¯è§åº¦è¿›è¡Œåˆæˆï¼šVIS\n",
    "vis15_mean['VIS']= np.where(vis15_mean['RVR_1A'] <=2000, vis15_mean['RVR_1A'], vis15_mean['MOR_1A'])\n",
    "vis12_mean['VIS']= np.where(vis12_mean['RVR_1A'] <=2000, vis12_mean['RVR_1A'], vis12_mean['MOR_1A'])\n",
    "\n",
    "\n",
    "data15 = ptu15_select.merge(vis15_mean,on = ['CREATEDATE','LOCALDATE (BEIJING)','SITE'] , how = 'inner')\n",
    "\n",
    "data15 = data15.merge(wind15_mean,on = ['CREATEDATE','LOCALDATE (BEIJING)','SITE'] , how = 'inner')\n",
    "\n",
    "\n",
    "data12 = ptu12_select.merge(vis12_mean,on = ['CREATEDATE','LOCALDATE (BEIJING)','SITE'] , how = 'inner')\n",
    "\n",
    "data12 = data12.merge(wind12_mean,on = ['CREATEDATE','LOCALDATE (BEIJING)','SITE'] , how = 'inner')\n",
    "\n",
    "# é‡æ–°ä¿å­˜\n",
    "df1215 = data15.copy()\n",
    "df1215.columns = ['CREATEDATE', 'LOCALDATE', 'SITE', 'PAINS', 'QFE',\n",
    "       'QNH', 'TEMP', 'RH', 'DEWPOINT', 'RVR_1A', 'MOR_1A', 'LIGHTS',\n",
    "       'VIS', 'WS2A', 'WD2A', 'CW2A']\n",
    "# #åˆ é™¤CW2Aä¸º0çš„è¡Œ\n",
    "# df1215 = df1215[df1215['CW2A'] != 0]\n",
    "# df1215.to_csv('df1215.csv')\n",
    "\n",
    "# é‡æ–°ä¿å­˜\n",
    "df0312 = data12.copy()\n",
    "df0312.columns = ['CREATEDATE', 'LOCALDATE', 'SITE', 'PAINS', 'QFE',\n",
    "       'QNH', 'TEMP', 'RH', 'DEWPOINT', 'RVR_1A', 'MOR_1A', 'LIGHTS',\n",
    "       'VIS', 'WS2A', 'WD2A', 'CW2A']\n",
    "# #åˆ é™¤CW2Aä¸º0çš„è¡Œ\n",
    "# df0312 = df0312[df0312['CW2A'] != 0]\n",
    "# df0312.to_csv('df0312.csv')\n",
    "\n",
    "## åˆæ­¥æ•°æ®å¯è§†åŒ–\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # æ­¥éª¤ä¸€ï¼ˆæ›¿æ¢sans-serifå­—ä½“ï¼‰\n",
    "plt.rcParams['axes.unicode_minus'] = False   # æ­¥éª¤äºŒï¼ˆè§£å†³åæ ‡è½´è´Ÿæ•°çš„è´Ÿå·æ˜¾ç¤ºé—®é¢˜ï¼‰\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#ç¯å…‰ã€å¯è§åº¦ã€æ—¶é—´\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.arange(len(df1215['CREATEDATE'])),df1215['LIGHTS'],'b',label=\"LIGHTS\")\n",
    "plt.plot(np.arange(len(df1215['CREATEDATE'])),df1215['VIS'],'r',label=\"VIS\")\n",
    "plt.legend(loc=\"upper right\") #æ˜¾ç¤ºå›¾ä¸­çš„æ ‡ç­¾\n",
    "# plt.xlabel(\"the number of sales\")\n",
    "# plt.ylabel('value of sales')\n",
    "plt.title('20191215')\n",
    "plt.show()\n",
    "\n",
    "#ç¯å…‰ã€å¯è§åº¦ã€æ—¶é—´\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.arange(len(df0312['CREATEDATE'])),df0312['LIGHTS'],'b',label=\"LIGHTS\")\n",
    "plt.plot(np.arange(len(df0312['CREATEDATE'])),df0312['VIS'],'r',label=\"VIS\")\n",
    "plt.legend(loc=\"upper right\") #æ˜¾ç¤ºå›¾ä¸­çš„æ ‡ç­¾\n",
    "# plt.xlabel(\"the number of sales\")\n",
    "# plt.ylabel('value of sales')\n",
    "plt.title('20200312')\n",
    "plt.show()\n",
    "\n",
    "## ä¸–ç•Œæ—¶é—´17:00-23:59 ä¸00:00-17:00 åˆ†æ®µå¤„ç†\n",
    "---\n",
    "ç›´è§‚çœ‹æ¥äº†LIGHTSå’Œå¯è§åº¦æ²¡æœ‰ä»€ä¹ˆå…³ç³»\n",
    "\n",
    "df,day = df1215.copy(),'2019/12/15'\n",
    "idx1 = df[df['CREATEDATE'] == day+ ' 6:00'].index\n",
    "idx2 = df[df['CREATEDATE'] == day +' 17:00'].index\n",
    "print(idx1,idx2)\n",
    "\n",
    "def dayCut(df):\n",
    "    dfd = df.iloc[360:1021,:]\n",
    "    return dfd\n",
    "\n",
    "df1d = dayCut(df1215)\n",
    "df2d = dayCut(df0312)\n",
    "\n",
    "## å°†ä¸¤å¤©ç™½å¤©çš„æ•°æ®åˆå¹¶\n",
    "\n",
    "df = pd.concat([df1d,df2d])\n",
    "\n",
    "## æ•°æ®é¢„å¤„ç†\n",
    "---\n",
    "RVRå’ŒMORåˆ†åˆ«ä¸ºä¸¤ç§å®šä¹‰ä¸‹çš„èƒ½è§åº¦ï¼Œå…¶ä¸­RVRâ‰¤2000ç±³ï¼ŒMORâ‰¤10000ç±³\n",
    "\n",
    "def dataPre(data15):\n",
    "    #å»é‡ å’Œå»ç©ºå€¼\n",
    "    data15.dropna(inplace = True)\n",
    "    data15.drop_duplicates(inplace = True)\n",
    "\n",
    "\n",
    "    #å»æå€¼\n",
    "    def filter_extreme_3sigma(series,n=3): #3 sigma\n",
    "        mean = series.mean()\n",
    "        std = series.std()\n",
    "        max_range = mean + n*std\n",
    "        min_range = mean - n*std\n",
    "    #     print(max_range)\n",
    "    #     print(min_range)\n",
    "        return np.clip(series,min_range,max_range)\n",
    "    for col in data15.columns:\n",
    "        if isinstance(data15[col].iloc[0],str):\n",
    "    #         print(col)\n",
    "            pass\n",
    "        else:\n",
    "            data15[col] = filter_extreme_3sigma(data15[col])\n",
    "\n",
    "\n",
    "    #æ ‡å‡†åŒ–\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## æ ‡å‡†åŒ–(ä½¿ç‰¹å¾æ•°æ®æ–¹å·®ä¸º1,å‡å€¼ä¸º0)\n",
    "\n",
    "    # ä½¿ç”¨sklearnçš„åŒ…\n",
    "    scaler = StandardScaler()\n",
    "    data_notstr = data15.iloc[:,3:].copy()\n",
    "    scaler.fit(data_notstr)                               # ä½¿ç”¨transfromå¿…é¡»è¦ç”¨fitè¯­å¥\n",
    "    data_notstr = scaler.transform(data_notstr)          # transfromé€šè¿‡æ‰¾ä¸­å¿ƒå’Œç¼©æ”¾ç­‰å®ç°æ ‡å‡†åŒ–\n",
    "#     fit_trans_data_2 = scaler.fit_transform(data_2)  # fit_transfromä¸ºå…ˆæ‹Ÿåˆæ•°æ®,ç„¶åè½¬åŒ–å®ƒå°†å…¶è½¬åŒ–ä¸ºæ ‡å‡†å½¢å¼\n",
    "    data15.iloc[:,3:] = data_notstr\n",
    "#     print('ä½¿ç”¨fit,transformæ ‡å‡†åŒ–çš„æ•°æ®:\\n', data15)\n",
    "#     print('ä½¿ç”¨fit_transformæ ‡å‡†åŒ–çš„æ•°æ®:\\n', fit_trans_data_2)\n",
    "    return data15\n",
    "\n",
    "\n",
    "# temp = df1215[(df1215.VIS!=5000) & (df1215.VIS!=6000) & (df1215.VIS!=7000) ].copy()\n",
    "df_pro = dataPre(df)\n",
    "\n",
    "\n",
    "## ç›¸å…³æ€§åˆ†æ\n",
    "\n",
    "df_pro.columns = ['CREATEDATE',\n",
    " 'LOCALDATE',\n",
    " 'SITE',\n",
    " 'PAINS',\n",
    " 'QFE',\n",
    " 'QNH',\n",
    " 'TEMP',\n",
    " 'RH',\n",
    " 'DEWPOINT',\n",
    " 'WS2A',\n",
    " 'WD2A',\n",
    " 'CW2A',\n",
    " 'RVR_1A',\n",
    " 'MOR_1A',\n",
    " 'LIGHTS',\n",
    " 'VIS']\n",
    "\n",
    "aa = df_pro.corr()\n",
    "aa.apply(lambda x: x.round(2))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set(font_scale=2) # font size 2\n",
    "sns.heatmap(df_pro.corr(), annot=True)\n",
    "plt.savefig(\"./ç»“æœ/heatmap.png\")\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set(font_scale=2) # font size 2\n",
    "sns.pairplot(df_pro[[\n",
    " 'PAINS',\n",
    " 'QFE',\n",
    " 'QNH',\n",
    " 'TEMP',\n",
    " 'RH',\n",
    " 'DEWPOINT',\n",
    " 'WS2A',\n",
    " 'WD2A',\n",
    " 'CW2A',\n",
    " 'VIS']],kind='reg')\n",
    "plt.savefig(\"./ç»“æœ/pairplot.png\")\n",
    "plt.show()\n",
    "\n",
    "## å¤šå…ƒçº¿æ€§å›å½’\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "data = df_pro.copy()\n",
    "# visualize the relationship between the features and the response using scatterplots\n",
    "feature_cols = ['PAINS','TEMP','RH','WS2A'] #'PAINS',\n",
    "flag_col = 'VIS'\n",
    "\n",
    "sns.set(font_scale=2) # font size 2\n",
    "sns.pairplot(data, x_vars=feature_cols[:2], y_vars='VIS', height=10, aspect=0.8, kind='reg')\n",
    "plt.savefig('./ç»“æœ/å…³é”®å˜é‡ç›¸å…³æ€§1.png')\n",
    "plt.show()#æ³¨æ„å¿…é¡»åŠ ä¸Šè¿™ä¸€å¥ï¼Œå¦åˆ™æ— æ³•æ˜¾ç¤ºã€‚\n",
    "\n",
    "\n",
    "sns.set(font_scale=2) # font size 2\n",
    "sns.pairplot(data, x_vars=feature_cols[2:], y_vars='VIS', height=10, aspect=0.8, kind='reg')\n",
    "plt.savefig('./ç»“æœ/å…³é”®å˜é‡ç›¸å…³æ€§2.png')\n",
    "plt.show()#æ³¨æ„å¿…é¡»åŠ ä¸Šè¿™ä¸€å¥ï¼Œå¦åˆ™æ— æ³•æ˜¾ç¤ºã€‚\n",
    "\n",
    "\n",
    "#seabornçš„pairplotå‡½æ•°ç»˜åˆ¶Xçš„æ¯ä¸€ç»´åº¦å’Œå¯¹åº”Yçš„æ•£ç‚¹å›¾ã€‚é€šè¿‡è®¾ç½®sizeå’Œaspectå‚æ•°æ¥è°ƒèŠ‚æ˜¾ç¤ºçš„å¤§å°å’Œæ¯”ä¾‹ã€‚\n",
    "#å¯ä»¥ä»å›¾ä¸­çœ‹å‡ºï¼ŒTVç‰¹å¾å’Œé”€é‡æ˜¯æœ‰æ¯”è¾ƒå¼ºçš„çº¿æ€§å…³ç³»çš„ï¼Œè€ŒRadioå’ŒSalesçº¿æ€§å…³ç³»å¼±ä¸€äº›ï¼ŒNewspaperå’ŒSalesçº¿æ€§å…³ç³»æ›´å¼±ã€‚\n",
    "#é€šè¿‡åŠ å…¥ä¸€ä¸ªå‚æ•°kind='reg'ï¼Œseabornå¯ä»¥æ·»åŠ ä¸€æ¡æœ€ä½³æ‹Ÿåˆç›´çº¿å’Œ95%çš„ç½®ä¿¡å¸¦ã€‚\n",
    "\n",
    "#create a python list of feature names\n",
    "# equivalent command to do this in one line\n",
    "X = data[feature_cols]\n",
    "y = data[flag_col]\n",
    "\n",
    "##æ„é€ è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "#default split is 75% for training and 25% for testing\n",
    "from sklearn.model_selection import train_test_split  #è¿™é‡Œæ˜¯å¼•ç”¨äº†äº¤å‰éªŒè¯\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y,test_size=0.25, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "model=linreg.fit(X_train, y_train)\n",
    "linreg.fit(X_train, y_train)\n",
    "print(model)\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)\n",
    "\n",
    "# pair the feature names with the coefficients\n",
    "print(flag_col+' = ',end = '')\n",
    "for i,j in zip(feature_cols, linreg.coef_):\n",
    "    print(f'({j.round(4)}) * {i} + ',end = '')\n",
    "print(f'({linreg.intercept_})')\n",
    "    \n",
    "\n",
    "---\n",
    "è¯„ä»·å›å½’é—®é¢˜\n",
    "    (1)å¹³å‡ç»å¯¹è¯¯å·®(Mean Absolute Error, MAE)\n",
    "\n",
    "    (2)å‡æ–¹è¯¯å·®(Mean Squared Error, MSE)\n",
    "\n",
    "    (3)å‡æ–¹æ ¹è¯¯å·®(Root Mean Squared Error, RMSE)\n",
    "\n",
    "# #æ¨¡å‹è¯„ä¼°\n",
    "\n",
    "# print(type(y_pred),type(y_test))\n",
    "# print (len(y_pred),len(y_test))\n",
    "# print (y_pred.shape,y_test.shape)\n",
    "# from sklearn import metrics\n",
    "# import numpy as np\n",
    "# sum_mean=0\n",
    "# for i in range(len(y_pred)):\n",
    "#     sum_mean+=(y_pred[i]-y_test.values[i])**2\n",
    "# sum_erro=np.sqrt(sum_mean/50)\n",
    "# # calculate RMSE by hand\n",
    "# print(\"RMSE by hand:\",sum_erro)\n",
    "#RMSEè¶Šå°è¶Šå¥½\n",
    "r_sq = model.score(X_test, y_test)\n",
    "print('TEST')\n",
    "print('coefficient of determination(ğ‘…Â²) :', r_sq)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('MSE:',MSE)\n",
    "print('RMSE:',RMSE)\n",
    "\n",
    "r_sq = model.score(X_train, y_train)\n",
    "print('TRAIN')\n",
    "print('coefficient of determination(ğ‘…Â²) :', r_sq)\n",
    "y_train_pred = model.predict(X_train)\n",
    "from sklearn import metrics\n",
    "MSE = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "print('MSE:',MSE)\n",
    "print('RMSE:',RMSE)\n",
    "\n",
    "# è®­ç»ƒé›†ç»˜å›¾\n",
    "plt.figure(figsize=(20,10))\n",
    "x = np.arange(len(X_train))\n",
    "y_train_hat = model.predict(X_train)\n",
    "plt.scatter(x,y_train)\n",
    "plt.plot(x, y_train_hat)\n",
    "plt.show()\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "'size' : 30,\n",
    "}\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']#é»‘ä½“\n",
    "# æµ‹è¯•é›†ç»˜å›¾\n",
    "y_pred = linreg.predict(X_test)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(range(len(y_pred)),y_pred,'b',label=\"é¢„æµ‹å€¼\")\n",
    "plt.plot(range(len(y_pred)),y_test,'r',label=\"çœŸå®å€¼\")\n",
    "plt.legend(loc=\"upper right\",prop = font) #æ˜¾ç¤ºå›¾ä¸­çš„æ ‡ç­¾\n",
    "# plt.title('æµ‹è¯•é›†å¯¹æ¯”å›¾')\n",
    "plt.ylabel(\"èƒ½è§åº¦\",font)\n",
    "plt.xlabel('æ—¶é—´ç‚¹',font)\n",
    "plt.savefig('./ç»“æœ/æµ‹è¯•é›†å¯¹æ¯”.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#ç»˜åˆ¶å¯¹æ¯”æ›²çº¿\n",
    "X1 = X.iloc[:661,:].copy()\n",
    "y1 = y.iloc[:661].copy()\n",
    "plt.figure(figsize=(20,10))\n",
    "x = np.arange(len(X1))\n",
    "y_hat = model.predict(X1)\n",
    "plt.scatter(x,y1,label = 'çœŸå®å€¼')\n",
    "plt.plot(x, y_hat,label = 'é¢„æµ‹å€¼')\n",
    "plt.legend(loc=\"upper right\",prop = font) #æ˜¾ç¤ºå›¾ä¸­çš„æ ‡ç­¾\n",
    "# plt.title('2019/12/15 èƒ½è§åº¦çœŸå®å€¼ä¸é¢„æµ‹å€¼å¯¹æ¯”å›¾')\n",
    "plt.ylabel(\"èƒ½è§åº¦\",font)\n",
    "plt.xlabel('æ—¶é—´ç‚¹',font)\n",
    "plt.savefig('./ç»“æœ/ç¬¬ä¸€å¤©å¯¹æ¯”.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X1 = X.iloc[661:,:].copy()\n",
    "y1 = y.iloc[661:].copy()\n",
    "plt.figure(figsize=(20,10))\n",
    "x = np.arange(len(X1))\n",
    "y_hat = model.predict(X1)\n",
    "plt.scatter(x,y1,label = 'çœŸå®å€¼')\n",
    "plt.plot(x, y_hat,label = 'é¢„æµ‹å€¼')\n",
    "plt.legend(loc=\"upper right\",prop = font) #æ˜¾ç¤ºå›¾ä¸­çš„æ ‡ç­¾\n",
    "# plt.title('2020/03/12 èƒ½è§åº¦çœŸå®å€¼ä¸é¢„æµ‹å€¼å¯¹æ¯”å›¾')\n",
    "plt.ylabel(\"èƒ½è§åº¦\",font)\n",
    "plt.xlabel('æ—¶é—´ç‚¹',font)\n",
    "plt.savefig('./ç»“æœ/ç¬¬äºŒå¤©å¯¹æ¯”.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## æ¨¡å‹è°ƒä¼˜\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(),y_test.max()], [y_test.min(),y_test.max()], 'k--')\n",
    "# plt.title('è®­ç»ƒé›†èƒ½è§åº¦')\n",
    "font1= font = {'weight' : 'normal',\n",
    "'size' : 30,\n",
    "}\n",
    "plt.xlabel('çœŸå®å€¼',font1)\n",
    "plt.ylabel('é¢„æµ‹å€¼',font1)\n",
    "plt.savefig('./ç»“æœ/æµ‹è¯•é›†VIS.png')\n",
    "plt.show()\n",
    "\n",
    "# ---\n",
    "#     åº”è¯¥å»é™¤å¼‚å¸¸å€¼<pr>\n",
    "#     å¯ä»¥çœ‹å‡ºVIS = 5000,6000ï¼Œ7000çš„æ—¶å€™æœ‰è¾ƒå¤šå¼‚å¸¸å€¼ï¼Œå› æ­¤å»é™¤è¿™äº›ç‚¹\n",
    "\n",
    "\n",
    "# # å»é™¤VIS = 5000,6000ï¼Œ7000çš„å¼‚å¸¸å€¼\n",
    "# drop_index = y[(y.values==5000) | (y.values==6000) | (y.values==7000)  ].index.values\n",
    "# X = X.drop(drop_index)\n",
    "# y = y.drop(drop_index)\n",
    "# # è¿™é‡Œåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‚æ•°random_stateéƒ½æ˜¯1ï¼Œè¡¨ç¤ºéšæœºåˆ†é…çš„æ•°æ®æ˜¯åŒä¸€ç»„\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "# # å¯¹è®­ç»ƒé›†è¿›è¡Œè®­ç»ƒ\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "# # å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹\n",
    "# y_pred = lr.predict(X_test)\n",
    "# MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "# RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# print('MSE:',MSE)\n",
    "# print('RMSE:',RMSE)\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.plot([y_test.min(),y_test.max()], [y_test.min(),y_test.max()], 'k--')\n",
    "# plt.title('MODIFY1')\n",
    "# plt.xlabel('REAL')\n",
    "# plt.ylabel('PRED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
